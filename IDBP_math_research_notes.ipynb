{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "y = Hx + e\n",
       "\\end{aligned}\n",
       "$$\n",
       "\\begin{aligned}\n",
       "degraded(i,j) = H[original(i,j)] + noise\n",
       "\\end{aligned}\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "y = Hx + e\n",
    "\\end{aligned}\n",
    "$$\n",
    "\\begin{aligned}\n",
    "degraded(i,j) = H[original(i,j)] + noise\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**y**: \"observations\" , m-sized vector  \n",
    "**x** : \"unknown orig image\", n-sized vector  \n",
    "**H**: \"degradation matrix\", (linear?) system operator m x n sized (e.g. denoising, inpainting, deblurring, etc... transform operator/function)  \n",
    "**e** : \"noise vector\", variables are **statistically indep** (P(AB) = P(A)P(B)) AND from the **same Standard Gaussian PDF** (Standard deviation 'e' seen in equations relates to this noise function/vector)\n",
    "![image_Restoration_model](https://images.slideplayer.com/26/8267441/slides/slide_5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the most appealing property of the proposed strategy is its minimal parameter tuning.Specifically, for the noisy inpainting problem, our method has a single parameter that can be just set to zero, and for the deblurring problem we suggest an automatic parameter tuning scheme that can be employed.\n",
    "\n",
    "Cost functions ~ Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image model prior, denoted as s(x), represents our prior knowledge or beliefs about the properties of the true image x that we are trying to estimate from the observed or degraded image y; s(x) allows us to leverage additional information, constraints and intial basis beyond what we have in y.\n",
    "s(x) captures the regularities, patterns, and constraints that we expect to hold true for presumed natural images. These priors are often based on statistical properties, perceptual considerations, or domain-specific knowledge about the structure of images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "f(\\tilde{x}) &= \\frac{1}{2\\sigma_e^2}*||y - \\bold{H}\\tilde{x}||_2^2 + s(\\tilde{x})  ~\\;\\; \\scriptsize(\\text{general}) \\\\\n",
       "             &\\implies min[\\ell(\\tilde{x}) + \\beta s(\\tilde{v})]  ~\\;\\; \\scriptsize(\\text{PnP, see paper refs})\n",
       "\\end{aligned}\n",
       "$$\n",
       "\\begin{aligned}\n",
       "lossfunc(i,j) &= gaussconst*(degraded - reconstructed) + betaParam*prior \\\\\n",
       "              &= dataFidelityTerm + regularizationTerm \n",
       "\\end{aligned}\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "f(\\tilde{x}) &= \\frac{1}{2\\sigma_e^2}*||y - \\bold{H}\\tilde{x}||_2^2 + s(\\tilde{x})  ~\\;\\; \\scriptsize(\\text{general}) \\\\\n",
    "             &\\implies min[\\ell(\\tilde{x}) + \\beta s(\\tilde{v})]  ~\\;\\; \\scriptsize(\\text{PnP, see paper refs})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\\begin{aligned}\n",
    "lossfunc(i,j) &= gaussconst*(degraded - reconstructed) + betaParam*prior \\\\\n",
    "              &= dataFidelityTerm + regularizationTerm \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P&P Framework proposes general recovery strategy and optimizations instead of making a complete algorithm to solve the above min(f(x_tilde)) for each type/operations of H matrices.\n",
    "> *P&P baselines:  (see refs 32 (ADMM with augmented lagrangian) and 15, as well as resources at refs 1,2,3... )*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
