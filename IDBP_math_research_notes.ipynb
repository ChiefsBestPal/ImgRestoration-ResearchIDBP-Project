{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "y = Hx + e\n",
       "\\end{aligned}\n",
       "$$\n",
       "\\begin{aligned}\n",
       "degraded(i,j) = H[original(i,j)] + noise\n",
       "\\end{aligned}\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "y = Hx + e\n",
    "\\end{aligned}\n",
    "$$\n",
    "\\begin{aligned}\n",
    "degraded(i,j) = H[original(i,j)] + noise\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**y**: \"observations\" , m-sized vector  \n",
    "**x** : \"unknown orig image\", n-sized vector  \n",
    "**H**: \"degradation matrix\", (linear?) system operator m x n sized (e.g. denoising, inpainting, deblurring, etc... transform operator/function)  \n",
    "**e** : \"noise vector\", variables are **statistically indep** (P(AB) = P(A)P(B)) AND from the **same Standard Gaussian PDF** (Standard deviation 'e' seen in equations relates to this noise function/vector)\n",
    "![image_Restoration_model](https://images.slideplayer.com/26/8267441/slides/slide_5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the most appealing property of the proposed strategy is its minimal parameter tuning.Specifically, for the noisy inpainting problem, our method has a single parameter that can be just set to zero, and for the deblurring problem we suggest an automatic parameter tuning scheme that can be employed.\n",
    "\n",
    "Cost functions ~ Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image model prior, denoted as s(x), represents our prior knowledge or beliefs about the properties of the true image x that we are trying to estimate from the observed or degraded image y; s(x) allows us to leverage additional information, constraints and intial basis beyond what we have in y.\n",
    "s(x) captures the regularities, patterns, and constraints that we expect to hold true for presumed natural images. These priors are often based on statistical properties, perceptual considerations, or domain-specific knowledge about the structure of images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "f(\\tilde{x}) &= \\frac{1}{2\\sigma_e^2}*||y - \\bold{H}\\tilde{x}||_2^2 + s(\\tilde{x})  ~\\;\\; \\scriptsize(\\text{general}) \\\\\n",
       "             &\\implies min[\\ell(\\tilde{x}) + \\beta s(\\tilde{v})]  ~\\;\\; \\scriptsize(\\text{PnP, see paper refs})\n",
       "\\end{aligned}\n",
       "$$\n",
       "\\begin{aligned}\n",
       "lossfunc(i,j) &= gaussconst*(degraded - reconstructed) + betaParam*prior \\\\\n",
       "              &= dataFidelityTerm + regularizationTerm \n",
       "\\end{aligned}\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "f(\\tilde{x}) &= \\frac{1}{2\\sigma_e^2}*||y - \\bold{H}\\tilde{x}||_2^2 + s(\\tilde{x})  ~\\;\\; \\scriptsize(\\text{general}) \\\\\n",
    "             &\\implies min[\\ell(\\tilde{x}) + \\beta s(\\tilde{v})]  ~\\;\\; \\scriptsize(\\text{PnP, see paper refs})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\\begin{aligned}\n",
    "lossfunc(i,j) &= gaussconst*(degraded - estimateReconstructed) + betaParam*prior \\\\\n",
    "              &= dataFidelityTerm + regularizationTerm \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P&P Framework proposes general recovery strategy and optimizations instead of making a complete algorithm to solve the above min(f(x_tilde)) for each type/operations of H matrices.\n",
    "> *P&P baselines:  (see refs 32 (ADMM with augmented lagrangian) and 15, as well as resources at refs 1,2,3... )*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "f(\\tilde{x}) &\\equiv \\frac{1}{2\\sigma_e^2}*||\\bold{H^{\\dagger}}y - \\tilde{x}||_{H^T H}^2 + s(\\tilde{x})  ~\\;\\; \\scriptsize(\\text{general base for paper's method}) \\\\\n",
       "             &\\implies min[f(\\tilde{x})]  ~\\;\\; \\scriptsize(\\text{See next equation block for proper estimator})\n",
       "\\end{aligned}\n",
       "$$\n",
       "\\begin{aligned}\n",
       "lossfunc(i,j) &= gaussconst*(transformedObservedData - reconstructed) + prior \\\\\n",
       "              &= dataFidelityTerm*possibleDegeneracy + regularizationTerm \n",
       "\\end{aligned}\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "f(\\tilde{x}) &\\equiv \\frac{1}{2\\sigma_e^2}*||\\bold{H^{\\dagger}}y - \\tilde{x}||_{H^T H}^2 + s(\\tilde{x})  ~\\;\\; \\scriptsize(\\text{general base for paper's method}) \\\\\n",
    "             &\\implies min[f(\\tilde{x})]  ~\\;\\; \\scriptsize(\\text{See next equation block for proper estimator})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\\begin{aligned}\n",
    "lossfunc(i,j) &= gaussconst*(transformedObservedData - reconstructed) + prior \\\\\n",
    "              &= dataFidelityTerm*possibleDegeneracy + regularizationTerm \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pseudo inverse of a full row rank matrix H m x n (m = rank < n) is a generalized form of the inverse of H that respects Moore-Penrose conditions. It is the product of its tranpose with the inverse of a symmetric matrix H H^T.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "positive definite matrix: all its eigen values are positive ; \"well behaved\"; vectors transformed by the matrix presever their length and direction\n",
    "\n",
    "H^T H is nxn and H H^T is mxm ... symmetric square matrix\n",
    "\n",
    "H^T H has a non-trivial null space meaning exists x != 0 such that Hx = 0 signifying that this **transformation on fidelity term ignores certain dimensions/components** of the H^T H vector space and thus the homogenous system Hx = 0 may lead to redundancy because there may be various different solutions. the seminorm of H^T H may be negative or nondefinite, as it is a generalized form that indicates magnitude of the vector/tensor its measuring \"relative\" to the H^T H basis. \n",
    "\n",
    "[1] To avoid degeneracy because of ignored components and to make a more pratical optimization problem, the semi norm is replaced by a L2 norm and a design parameter 'delta' is included as a uncertainty/delta design parameter.\n",
    "The gaussian constant is thus now: 1/2(sigma_e + delta)^2\n",
    "\n",
    "[2] the delta parameter may make the numerical effect/amplitude of the data fidelity term ill-conditionned in certain cases if it is not picked adequaltely. \n",
    "To have a stable distribution and proper statistical estimators for x and y, minimize correctly the gaussian constant denominator with respect to delta:\n",
    "\n",
    "delta = argmin_delta [(sigma_e + delta_tilde)]^2  such that f(x_tilde) >= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "f(\\tilde{x}) &\\equiv \\frac{1}{2\\sigma_e^2}*||\\bold{H^{\\dagger}}y - \\tilde{x}||_{H^T H}^2 + s(\\tilde{x})  ~\\;\\; \\scriptsize(\\text{general base for paper's method}) \\\\\n",
    "             &\\implies min[f(\\tilde{x})]  ~\\;\\; \\scriptsize(\\text{See next equation block for proper estimator})\n",
    "\\end{aligned}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    TODO: EXPLAIN WITH DESCRIPTION OF DATASETS HOW WITH IDBP+BM3D CHANGING THE NOISE FUNCTION STANDARD DEVIATION sigma_e IN PARAMETER TUNING VARIES SO MUCH ITERATION PER ITERATION, CASE BY CASE AND/OR IMAGE BY IMAGE ??? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
